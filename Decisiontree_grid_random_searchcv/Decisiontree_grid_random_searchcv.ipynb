{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN3AoGQM1xp9g6+goTAN1Kt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/keshav123333/Machine_learning_100_campusx/blob/main/Decisiontree_grid_random_searchcv/Decisiontree_grid_random_searchcv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#decision tree\n",
        "\n",
        "1. isme hum basically data ko colun ke basis pe karte split isko aise bhi le sakta jaise ye hai if else loop in computer ek best if else loop banata hai\n",
        "\n",
        "\n",
        "2. Ab second cheez hume ek aur cheez karni chaiye ki hum kaise bhi isko rok sake matlab hum entropy less wla data lete entropy more means more randomenss hume aisa split ki kam cheez randomness aur data niche suttle ho jaye\n",
        "\n",
        "3. entropy= sum(plogp)  and  isme hum ye karte hi rehte hai jab tak ki kuch ho na jaye ya entrpy zero na ho jaye isme pehle parent ka entropy cal\n",
        "\n",
        "then fir ek col lete uske basis pe split karte then uska entroy nikalte then weghted entropy nklte and info gain nikalte by minus wiegthed entropy with parent entropy\n",
        "\n",
        "same cheez gini value =1-sum(p1^2+p2^2+...) aise and same cheez se iske liye bhi niklate hai info gain bas ye computationally kam hota as isme hum plus minus karte and entropy gan mein log lete hai\n",
        "\n",
        "\n",
        "video dekh pure ke liye [link text](https://www.youtube.com/watch?v=IZnno-dKgVQ&list=PLKnIA16_Rmvbr7zKYQuBfsVkjoLcJgxHH&index=80)"
      ],
      "metadata": {
        "id": "OcWX3EP9wHrh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "metadata": {
        "id": "-l9fuGqqhiOv"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "hyperparameter :     \n",
        "1. splitter- best ye best ko chunta hai , but isme random bhi bhejte as usse overfitting reduce hota hai\n",
        "2. max_depth= if none toh vo jitna chahe utna failta baki isse kam kar sakte of overfitting ho toh\n",
        "\n",
        "3. min sample split -> like if ek split ho raha kiss basis pe toh usme kitni min row maan 100 toh if ek spilt usme 79 hi row bachi so aur nich usse split nahi karga as if aur niche split hona toh 100 se jayada rows honi chaiye uss node ke pas isse jitna jayda baduayega utna overfit kam hoga as fir vo choti rows ko classfiy ni karga\n",
        "\n",
        "4. max feature -> like randomenss badne ke liye like ek jagah pe split karna tha toh vo sari row ka info gain niklaega then unme se ek chun ke hume best wale pe split toh if 3 diya tumne isme and 10 col hai so 10 m se 3 random slect honge and un teen pe hi info gain cal and split hoga isse randomenss ati overit reduce\n",
        "\n",
        "5. max leaf node =kitni node honge split ke tme\n",
        "\n",
        "6. min impurity dec -> ye set ki kitna impurity dec ho ki hum split kare aage isko hum khud slect kar sakte if iski value badayega toh vo hi hai split kam honge overfit kam dekh lena\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gvaAnpEu1XHC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#regression tree\n",
        "[link text](https://www.youtube.com/watch?v=RANHxyAvtM4&list=PLKnIA16_Rmvbr7zKYQuBfsVkjoLcJgxHH&index=82)"
      ],
      "metadata": {
        "id": "49eIPC5J4YxJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "metadata": {
        "id": "FUlHsNfD1Wdl"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = fetch_california_housing()\n",
        "X = data.data\n",
        "y = data.target"
      ],
      "metadata": {
        "id": "oWibn1x566Uo"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "X_twtAr07NaP"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tree_reg = DecisionTreeRegressor(random_state=42)"
      ],
      "metadata": {
        "id": "pSLp18dL7TGp"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'criterion': ['squared_error', 'friedman_mse', 'absolute_error'],\n",
        "    'max_depth': [None, 5, 10, 15, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}"
      ],
      "metadata": {
        "id": "U0NxRO587Wj2"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search = GridSearchCV(\n",
        "    estimator=tree_reg,\n",
        "    param_grid=param_grid,\n",
        "    cv=2, #yaha pe aur daal sakte ye utni baar train karta and avergae deta hai uske basis pe select\n",
        "    scoring='neg_mean_squared_error',\n",
        "    n_jobs=-1\n",
        ")\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"ðŸŒŸ Best Parameters from GridSearchCV:\")\n",
        "print(grid_search.best_params_)\n",
        "print(\"Best Score:\", -grid_search.best_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJUTjDmm7bf5",
        "outputId": "52dc7314-19fb-44c4-f54b-6380660c708c"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸŒŸ Best Parameters from GridSearchCV:\n",
            "{'criterion': 'absolute_error', 'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 10}\n",
            "Best Score: 0.4176790999988781\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = grid.best_estimator_ #if best estimator wala model chaiye toh"
      ],
      "metadata": {
        "id": "G7n-qKHL8r7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_search = RandomizedSearchCV(\n",
        "    estimator=dt,\n",
        "    param_distributions=param_grid,\n",
        "    n_iter=10,          # Try 10 random combinations\n",
        "    cv=5,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"\\nðŸŒŸ Best Parameters from RandomizedSearchCV:\")\n",
        "print(random_search.best_params_)\n",
        "print(\"Best Score:\", -random_search.best_score_)\n",
        "\n",
        "# ===============================\n",
        "# ðŸ”¹ Step 7: Evaluate on Test Data\n",
        "# ===============================\n",
        "best_model = random_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"\\nâœ… Test MSE of Best Model:\", mse)"
      ],
      "metadata": {
        "id": "x0fQLrnl7eB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visalize karne ke liye\n",
        "\n",
        "video dekh imp hai [link text](https://www.youtube.com/watch?v=SlMZqfvl5uw&list=PLKnIA16_Rmvbr7zKYQuBfsVkjoLcJgxHH&index=83)"
      ],
      "metadata": {
        "id": "6d4NKQEo-HuA"
      }
    }
  ]
}